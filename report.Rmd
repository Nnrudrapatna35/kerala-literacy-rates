---
title: "Understanding Literacy Rates in Rural Villages of the Indian State of Kerala"
author: "Nagaprasad Rudrapatna, Garrett Allen, Thomas Huck, and Kevin Ordet"
date: "December 16, 2022"
output:  
  pdf_document:
    number_sections: yes
header-includes:
- \usepackage{float}
- \floatplacement{figure}{H}
---

```{r setup, include = FALSE}
library(tidyverse)
library(sf)
library(ggplot2)
library(broom.mixed)
library(patchwork)
library(spdep)
library(janitor)
library(car)
library(mosaic)
library(yardstick)
library(ape)
library(knitr)
library(brms)
opts_chunk$set(echo = FALSE, warning = FALSE, message = F)
```

# Introduction and Data Description


Despite significant development in recent decades, many rural communities in the Indian state of Kerala still face significant socioeconomic challenges, which may be exacerbated by lack of access to nearby towns, caste discrimination, and gender inequality. Given the importance of literacy in the modern world, illiteracy remains an important indicator of which communities are most vulnerable. 


In this report, we aim to model the relationship between school infrastructure, caste, income, and literacy rate among rural villages in Kerala. For this project, we will be using data sourced from the NASA Socioeconomic Data and Applications Center (SEDAC) as described in Meiyappan et al. (2018), which uses data from the 2001 census of India, collected at the Village Directory and Primary Census Abstract levels, which can be reconciled using semi-automatic mappings from these results to villages via their unique village IDs. Since these levels both exist only for rural villages, we focus our analysis on the rural portions of the state of Kerala so that we have the relevant covariate data available. The boundaries for these villages were obtained from analog cadastral maps of the Survey of India. This imperfect mapping, alongside other inconsistencies, may lead to inaccuracies in the data. Also, the authors noted if every value for each variable was 0 from a particular data source, then those values were missing; we have excluded all such data from our analysis, which were just urban towns. 

# Exploratory Data Analysis 

```{r read data}
data <- read_sf("kerala/india-village-census-2001-KL.shp")

data2 <- data %>%
  select(UID, NAME_1, LEVEL, TRU, No_HH, TOT_P, TOT_M, TOT_F, P_06, M_06, F_06, P_SC, M_SC, F_SC, P_LIT, M_LIT, F_LIT, P_ILL, M_ILL, F_ILL, TOT_WORK_P, TOT_WORK_M, TOT_WORK_F, P_SCH, M_SCH, S_SCH, S_S_SCH, COLLEGE, IND_SCH, TR_SCH, ADLT_LT_CT, OTH_SCH, ALL_HOSP, AYU_HOSP, UN_HOSP, HOM_HOSP, MCW_CNTR, N_HOME, CWC, H_CNTR, CWC, DRNK_WAT_F, P_T_FAC, POST_OFF, BS_FAC, RS_FAC, BANK_FAC, RC_FAC, C_V_HALL, ST_AU_FAC, DIST_TOWN, POWER_SUPL, TOT_INC, TOT_EXP, MAN_COMM1, MAN_COMM2, MAN_COMM3)

#adding literacy rates / removing bad observations with missing values everywhere
kerala_data_adj <- data2 %>% 
  mutate(literacy_rate = P_LIT / TOT_P,
         literacy_rate_f = F_LIT / TOT_F,
         literacy_rate_m = M_LIT / TOT_M,
         scheduled_perc = P_SC / TOT_P + .000001,
         primary_school_r = P_SCH / P_06 * 100,
         middle_school_r = M_SCH / P_06 * 100,
         secondary_school_r = S_SCH / P_06 * 100,
         net = TOT_INC - TOT_EXP + 1,
  ) %>% 
  filter(!is.na(TRU)) %>% 
  mutate(across(.cols = where(is.character), as.factor)) %>% 
  filter(TOT_INC > 0)
```

```{r corr matrix, include = FALSE}
corr_matrix <- kerala_data_adj %>% 
  select(where(is.numeric)) %>% 
  tibble() %>% 
  select(-geometry) %>% 
  cor()

corr_w_lit_rate <- corr_matrix["literacy_rate",]

corr_w_lit_rate[abs(corr_w_lit_rate) > .1]

# we picked out DIST_TOWN, middle_school_r, scheduled_perc, and TOT_INC
```


```{r making EDA plots, fig.width = 7, fig.height = 3}
lit_perc <- kerala_data_adj %>% 
  ggplot(aes(y = literacy_rate, x = scheduled_perc)) + 
  geom_point() + 
  labs(title = "No clear association",
       y = "Literacy Rate",
       x = "Scheduled Caste Proportion") + 
  theme_bw()

lit_middle <- kerala_data_adj %>%
  ggplot(aes(y = literacy_rate, x = middle_school_r)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  labs(title = "Slight positive association",
       y = "Literacy Rate",
       x = "Number of Middle Schools Per Child") + 
  theme_bw()

lit_inc <- kerala_data_adj %>% 
  filter(TOT_INC < 10000000) %>% 
  ggplot(aes(y = literacy_rate, x = TOT_INC)) + 
  geom_point() + 
  theme_bw() + 
  labs(title = "No clear association",
       x = "Total Village Income",
       y = "Literacy Rate")

lit_dist <- kerala_data_adj %>% 
  ggplot(aes(y = literacy_rate, x = DIST_TOWN)) + 
  geom_point() + 
  theme_bw() + 
  labs(title = "Slight negative association",
       x = "Distance from Nearest Town",
       y = "Literacy Rate") + 
  geom_smooth(method = "lm")

EDA <- (lit_middle + lit_perc) / (lit_dist + lit_inc)

EDA + plot_annotation(title = "EDA shows that two variables seem correlated with literacy rate")
```

```{r literacy rates, fig.height = 6, fig.width = 8}
lit_tot <- kerala_data_adj %>% 
  ggplot() + 
  geom_sf(aes(fill = literacy_rate)) +
  scale_fill_viridis_c() + 
  theme_bw() + 
  labs(title = "Distribution of Literacy Rates Across Rural Kerala")

lit_tot
```

Our team decided to examine literacy rates among rural populations in the Indian state of Kerala. Since the raw dataset provided the number of literate people and the total population in each village, we divided the two to obtain the literacy rate for each village. We also calculated literacy rates among females and males, respectively, using the literacy and population information subsetted by gender. We considered the proportion of each village’s population that is classified as a scheduled caste person (i.e., sub-communities within the framework of the Hindu caste system who have historically faced deprivation, oppression, and extreme social isolation in India on account of their perceived ‘low status’) and also calculated village-level proportions for primary, middle, and secondary school availability (by dividing the number of schools in a given village by the number of children aged between 0 and 6 living within that village). We later discovered that, due to numerical issues (e.g., log(0) appearing), we needed to perturb our covariate values slightly. Each of these variables, along with the distance to the nearest town from a given village (in kilometers), total income (measured in terms of the 2000 rupee; snapshot of economic health), and several others, were considered during preliminary exploratory analysis as potentially relevant covariates. 


To gain a better understanding of the dataset, we performed exploratory data analysis. We started by examining a correlation matrix (with an eye towards high correlations between reasonable covariates and the literacy rate of a village; e.g., the female literacy rate had a near-perfect positive correlation with the overall literacy rate, but this covariate was not considered). We selected the distance to the nearest town, the middle school availability proportion (the number of middle schools per child), the scheduled caste proportion, and the total income as promising covariate variables since they were correlated with literacy rate (but not too heavily correlated with each other; avoiding issues of multicollinearity). We then created bivariate EDA plots to examine the relationships between each of the four covariates and the literacy rate (response variable). These plots (shown above) provide preliminary visual evidence of a weak positive association between the number of middle schools per child and literacy rate, as well as a weak negative association between the distance from the nearest town and the literacy rate. The EDA does not, however, provide visual evidence of an association between total income and literacy rate nor between scheduled caste proportion and literacy rate. Finally, we visualized the spatial distribution of literacy rates across the 1,209 rural villages in Kerala. Our key takeaway was that the literacy rates are lowest along the right border of the state (shared with Tamil Nadu) but relatively consistent across the heart of the state (i.e., through the center).


# The GLM without a spatial component

```{r standardizing}
kerala_data_adj <- kerala_data_adj %>% 
  mutate(middle_school_r = zscore(middle_school_r),
         scheduled_perc = zscore(scheduled_perc),
         DIST_TOWN = zscore(DIST_TOWN),
         TOT_INC = zscore(TOT_INC)
  )
```

```{r fitting an initial model}
initial_model <- glm(P_LIT ~ middle_school_r + offset(log(TOT_P))
                     + TOT_INC + DIST_TOWN + scheduled_perc, 
                     family = "poisson", 
                     data = kerala_data_adj)

tidy(initial_model) %>%
  kable(digits = 4, conf.int = T)
```


We fit a Poisson offset model with response variable literacy rate and predictor
variables distance to the nearest town, the middle school availability proportion (number of middle schools per child aged 0-6), the scheduled caste proportion, and the total income.

* For a rural village in Kerala with no middle schools (so that the number of middle schools per child is zero), a total income of zero rupees (based on the value of the 2000 rupee), the closest neighboring town being zero kilometers away, and no scheduled caste persons (so that the scheduled caste proportion is zero), our model predicts that the literacy rate is expected to be 0.793.

Below are the interpretations of each of the regression coefficients, holding all other
variables in the model constant:

* For every 0.01 (i.e., one absolute percentage point) increase in the number of middle schools per child aged between 0 and 6, a Keralite village's literacy rate is expected to be multiplied by 1.026.

* For every one rupee increase in the total income, a Keralite village's literacy rate is expected to be multiplied by 1.003.

* For every one kilometer increase in the distance to the nearest town, a Keralite village's literacy rate is expected to be multiplied by 0.986.

* For every 0.01 increase in the proportion of the total population that is classified as belonging to a scheduled caste, a Keralite village's literacy rate is expected to be multiplied by 0.996.

Although the standardized coefficient estimates are statistically significant (negligible p-values), they are very small in magnitude. This means that, although there is statistically significant evidence that these covariates are important in understanding the response, their respective impacts are relatively minor. 

We can visualize how well our model is doing by looking at the residual chloropleth
plots.


```{r residual chloropleth, fig.width = 8, fig.height = 6}
residuals <- initial_model %>%  
  augment(type.predict = "response",
          type.residuals = "deviance") %>% 
  mutate(predicted_diff = P_LIT - .fitted) %>% 
  mutate(geometry = kerala_data_adj$geometry) %>% 
  st_as_sf()

residuals %>% 
  ggplot() + 
  geom_sf(aes(fill = predicted_diff)) + 
  scale_fill_viridis_c() + 
  theme_bw() + 
  labs(title = "Underpredicts on the right edge, overpredicts elsewhere")
```

From these chloropleth plots, we can see that the model is doing a fairly poor
job at predicting the number of literate people in an area (and thus the literacy rate).
The model underpredicts on the right border of the state, and everywhere else
the model tends to underpredict the number of literate people. 

We can also examine residual plots to see how well our model is doing: 


```{r residual plot, fig.width = 3.5, fig.height = 3}
raw_residual_plot <- residuals %>% 
  ggplot(aes(x = .fitted, y = predicted_diff)) + 
  geom_point() + 
  theme_bw() + 
  labs(x = "Number of Literate people (fitted)",
       y = "Raw Residuals",
       title = "Raw Residual Plot")

deviance_residual_plot <- residuals %>% 
  ggplot(aes(x = .fitted, y = .resid)) + 
  geom_point() + 
  theme_bw() + 
  labs(x = "Number of Literate people (fitted)",
       y = "Deviance Residuals",
       title = "Deviance Residual Plot")

raw_residual_plot
deviance_residual_plot
rmse_no_car <- tibble(rmse = rmse_vec(residuals$.fitted, residuals$P_LIT))
kable(rmse_no_car)
```


From this residual plot, we can see that while no assumptions are violated,
it isn't doing a particularly good job at predicting, as the residuals are pretty 
high for many of the points. The RMSE also supports this, as the RMSE is fairly
high (768.08). 


We thought that our model may be performing poorly because we didn't take into
account the spatial autocorrelation that should be present in the data. Since
this is areal data, it may be beneficial to add a latent CAR/SAR component to
our regression model. 


To see if a CAR/SAR model would be appropriate, we first performed a Moran's I test
for spatial autocorrelation on the residuals of our previous model. 


```{r assessing spatial correlation and creating A}
A = st_touches(residuals, sparse = FALSE) 
listW = mat2listw(A)
moran_out1 <- Moran.I(residuals$.resid, weight = A, na.rm = TRUE)

tibble(observed = moran_out1$observed,
       expected = moran_out1$expected,
       sd = moran_out1$sd, 
       pvalue = moran_out1$p.value) %>% 
  kable(digits = 4)


rownames(A) = kerala_data_adj$NAME_1
```

From the test conducted above, we see that the p-value is extremely low (<.001)
so that we can conclude there is likely spatial autocorrelation unaccounted for
in our Poisson regression model. We therefore decided to try to fit a latent
CAR model, along with our predictors. We also fit an intercept-only CAR model
as a baseline to assess how important our covariates are to prediction of 
literacy rate. For simplicity due to the lack of available tooling for latent
CAR models, we fit an intrinsic conditional autoregressive model (ICAR model)
since this model fits well with brms. 

# The GLM with a latent spatial component

```{r loading data}
load(file = "car_lit.RData")
load(file = "intercept_lit.RData")
```

```{r fitting intercept-only model, eval = FALSE}
intercept_lit = brm(
  P_LIT ~  offset(log(TOT_P)) + car(A, gr = NAME_1, type = "icar"), 
  data = kerala_data_adj, data2 = list(A = A), 
  family = poisson, cores = 4, iter = 12000, chains = 4, thin = 10)
```

```{r fig.height = 3}
summary_int <- summary(intercept_lit)

tidy(intercept_lit) %>% 
  select(-c(effect:term)) %>% 
  mutate(coefficient = c("Intercept"),
         Rhat = summary_int$fixed[["Rhat"]],
         Bulk_ESS = summary_int$fixed[["Bulk_ESS"]],
         Tail_ESS = summary_int$fixed[["Tail_ESS"]]) %>% 
  select(coefficient,estimate,std.error,conf.low,conf.high, Rhat, Bulk_ESS, Tail_ESS) %>% 
  kable(digits = 3)

plot(intercept_lit)
```

From the above trace plots, we can see that our intercept-only model converged,
as the traceplots look like random noise. Our Rhat also suggests convergence since it is near 1. 
We ran the plots for 12000 iterations with 5000 warmups cycle and thinned our chain by every 10th sample. 


Similarly, from the below trace plots and Rhat values, we see that our model with covariates
and a latent ICAR component converged with the same specifications as our 
intercept-only model. Our standardized coefficient estimates are extremely 
small and near-zero, and while the credible intervals do not contain zero, we
are skeptical that they are adding much to our predictive performance. We
will first assess if our covariates are useful before performing any further
inference on these covariates.

```{r fitting covariate model, eval = FALSE}
car_lit = brm(
  P_LIT ~  offset(log(TOT_P)) + TOT_INC + DIST_TOWN + middle_school_r + scheduled_perc + car(A, gr=NAME_1, type = "icar"), 
  data = kerala_data_adj, data2 =  list(A = A), 
  family = poisson, cores = 4, iter = 12000, chains = 4, thin = 10 
)
```

```{r}
summary_cov <- summary(car_lit)

tidy(car_lit) %>% 
  select(-c(effect:term)) %>% 
  mutate(coefficient = c("Intercept", "TOT_INC", "DIST_TOWN", "middle_schooL_r", "scheduled_perc"),
         Rhat = summary_cov$fixed[["Rhat"]],
         Bulk_ESS = summary_cov$fixed[["Bulk_ESS"]],
         Tail_ESS = summary_cov$fixed[["Tail_ESS"]]) %>% 
  select(coefficient,estimate,std.error,conf.low,conf.high, Rhat, Bulk_ESS, Tail_ESS) %>% 
  kable(digits = 3)

plot(car_lit)
```


Now that we've fit our two models using brms, we will compare their predictive 
performance using residual chloropleth plots, residual plots, and calculation of
RMSE. 

```{r creating prediction dataframes}
intercept_predict <- as.data.frame(predict(intercept_lit)) %>% 
  mutate(truth = kerala_data_adj$P_LIT) %>% 
  mutate(residuals = truth - Estimate)

covariate_predict <-  as.data.frame(predict(car_lit)) %>% 
  mutate(truth = kerala_data_adj$P_LIT) %>% 
  mutate(residuals = truth - Estimate) %>% 
  mutate(geometry = kerala_data_adj$geometry)
```

```{r residual plots for ICAR models, fig.height = 3}
int_car <- intercept_predict %>% 
  ggplot() + 
  geom_point(aes(x = Estimate, y = residuals)) + 
  theme_bw() + 
  labs(title = "Residuals of Null Model",
       x = "Fitted Values",
       y = "Residuals")

cov_car <- covariate_predict %>% 
  ggplot() + 
  geom_point(aes(x = Estimate, y = residuals)) + 
  theme_bw() + 
  labs(title = "Residuals of Covariate Model",
       x = "Fitted Values",
       y = "Residuals")

cov_car + int_car
```


From the two models, we can see that the residual plots are virtually identical, 
suggesting that our covariates aren't doing much to improve predictive performance
after accounting for the latent spatial structure. However, the residual plots
look significantly better than the poisson model without an ICAR component, and
the residuals are much lower. For the previous model, most villages had an error
in the hundreds or even thousands, whereas with this model, most villages
have errors in the tens. Both of these models are clearly doing a lot better than
our non-spatial model, but we should look at chloropleth plots and RMSE to understand
how much better it's doing.

```{r summary stats, fig.height = 6, fig.width = 8}
rmse_int <- rmse_vec(intercept_predict$Estimate, intercept_predict$truth)
rmse_cov <- rmse_vec(covariate_predict$Estimate, covariate_predict$truth)

tibble(rmse_cov = rmse_cov, rmse_int = rmse_int) %>% 
  kable()
```


From the RMSE, we can see that the each model is doing much better, as our 
previous RMSE was around 760, while both of these models have an RMSE near 100,
a 7 fold improvement in accuracy. However, it does indicate that, after accounting
for spatial autocorrelation, our covariates are basically useless for predictive
performance, since the intercept-only model and the covariate model have near
identical RMSE. 

Given that the models are identical, with the covariate version having a slightly
better RMSE, we should now compare our how well our covariate model does 
compared to the ground truth. To do this, we will visualize our fitted number
of literate people vs. the true number in a chloropleth plot. 

```{r plotting chloropleth}
predicted_values_geom <- covariate_predict %>% 
  st_as_sf() %>% 
  ggplot() + 
  geom_sf(aes(fill = Estimate)) + 
  theme_bw() + 
  scale_fill_viridis_c() + 
  labs(title = "Predicted literates")

true_values_geom <- covariate_predict %>% 
  st_as_sf() %>% 
  ggplot() + 
  geom_sf(aes(fill = truth)) + 
  theme_bw() + 
  scale_fill_viridis_c() + 
  labs(title = "Actual literates")

combined <- predicted_values_geom + true_values_geom

combined + plot_annotation(title = "CAR model has high prediction accuracy",
                           subtitle = "Predicted and truth look almost identical")
```


As we can see from the above plots, the true plot and the fitted plot look
virtually identical; our model is doing an extremely good job of predicting 
the number of literate people. This may be a byproduct of overfitting, but since
spatial cross validation is extremely non-trivial, we will not be testing for overfitting here. 


Our final step in model assessment is to see if our covariate model accounted
for all of the spatial correlation seen in the data. To do this, we created
a chloropleth plot of the residuals from our model below: 


```{r spatial correlation}
covariate_predict %>% 
  st_as_sf() %>% 
  ggplot() + 
  geom_sf(aes(fill = residuals)) + 
  scale_fill_viridis_c() + 
  theme_bw() + 
  labs(title = "Most residuals are near zero")
```


As we can see, the residuals are pretty much the same everywhere; there doesn't
appear to be any leftover spatial autocorrelation. A Moran's I test for spatial autocorrelation (seen below) also shows that our model has accounted for all such correlation, as our p-value is extremely high.


```{r morans I}
moran_out2 <- Moran.I(covariate_predict$residuals, A)

tibble(observed = moran_out2$observed,
       expected = moran_out2$expected,
       sd = moran_out2$sd, 
       pvalue = moran_out2$p.value) %>% 
  kable(digits = 4)
```


# Discussion of Results

From these models, we can broadly glean two results: 

1) that given covariates alone, literacy rates in rural Kerala are fairly hard to predict

2) spatial modeling alone captures literacy rates significantly better than 
a covariate model.

Our coefficients for our covariates do suggest certain interpretations of 
what drives literacy rates. For example, higher rates of 
scheduled castes in a location leading to lower literacy rate makes sense due
to historical oppression of these groups. Additionally, being far from other 
towns makes sense that it would increase illiteracy (due to lack of contact
and resources with other places). Meanwhile, more schools and more income 
should reasonably lead to increased levels of literacy. All of these coefficient
estimates should be taken lightly given that modeling literacy rates with an
ICAR model did far better, but it is worth mentioning that the directions make sense. 

For future work, it would be worth expanding this analysis to other states in
India to see if there are different trends depending on the type of region. 
Additionally, it would be worthwhile to do some cross validation on our model,
to see if our model is being dramatically overfitted. It would also be interesting
to add other covariates to our model from other data sources, or analyze some
of these trends over time, as we also have data from the 1990 census.


```{r saving data, eval = FALSE}
save(car_lit, file = "car_lit.RData")
save(intercept_lit, file = "intercept_lit.RData")
```
